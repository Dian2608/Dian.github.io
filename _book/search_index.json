[["index.html", "Portfolio Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " Portfolio Dian Dupon 2023-05-21 Chapter 1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["c.-elegans-offspring-count-with-different-components.html", "Chapter 2 C. elegans offspring count with different components” 2.1 Installing packages 2.2 Importing the data 2.3 Scatterplot of the C. elegans plate experiment 2.4 Normalizing the data ", " Chapter 2 C. elegans offspring count with different components” 2.1 Installing packages # install.packages(&quot;gitcreds&quot;) # library(gitcreds) # gitcreds_set() 2.2 Importing the data For this experiment the data from the CE.LIQ.FLOW.062_Tidydata.xlsx file was used to determine the effect of compound concentrations on offspring count and whether the different compounds have a positive effect on the amount of offspring. After importing the data, the data types of columns were checked to see if these were correctly assigned. # Loading library library(tidyverse) library(readxl) # Getting the data from the downloaded Excel file # You can find the raw data in the Data_raw folder of this experiment elegans_data &lt;- read_excel(&quot;~/DSFB2/dsfb2_workflows_portfolio/Portfolio/C.elegans_experiment/Data_raw/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;) # Check if the data imported correctly head(elegans_data) ## # A tibble: 6 × 34 ## plateRow plateColumn vialNr dropCode expType expReplicate expName ## &lt;lgl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 NA NA 1 a experiment 3 CE.LIQ.FLOW.062 ## 2 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 ## 3 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 ## 4 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 ## 5 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 ## 6 NA NA 2 a experiment 3 CE.LIQ.FLOW.062 ## # ℹ 27 more variables: expDate &lt;dttm&gt;, expResearcher &lt;chr&gt;, expTime &lt;dbl&gt;, ## # expUnit &lt;chr&gt;, expVolumeCounted &lt;dbl&gt;, RawData &lt;dbl&gt;, compCASRN &lt;chr&gt;, ## # compName &lt;chr&gt;, compConcentration &lt;chr&gt;, compUnit &lt;chr&gt;, ## # compDelivery &lt;chr&gt;, compVehicle &lt;chr&gt;, elegansStrain &lt;chr&gt;, ## # elegansInput &lt;dbl&gt;, bacterialStrain &lt;chr&gt;, bacterialTreatment &lt;chr&gt;, ## # bacterialOD600 &lt;dbl&gt;, bacterialConcX &lt;dbl&gt;, bacterialVolume &lt;dbl&gt;, ## # bacterialVolUnit &lt;chr&gt;, incubationVial &lt;chr&gt;, incubationVolume &lt;dbl&gt;, … # Check data types of specific columns str(elegans_data$RawData) ## num [1:360] 44 37 45 47 41 35 41 36 40 38 ... str(elegans_data$compName) ## chr [1:360] &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; ... str(elegans_data$compConcentration) ## chr [1:360] &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; ... The data type of the column compConcentration has not been correctly assigned during the importing of the data into R. Therefore we need to change the data type of this column. # Change column data type to numeric elegans_data_tidy &lt;- transform(elegans_data, compConcentration = as.numeric(compConcentration)) # Check if it is correctly assigned str(elegans_data_tidy$compConcentration) ## num [1:360] 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 ... After making the data from the excel file tidy a scatterplot is created to study the data of the plate experiment more thoroughly. 2.3 Scatterplot of the C. elegans plate experiment # Load library library(ggplot2) # Creating the scatterplot elegans_data_tidy %&gt;% ggplot(aes(x=log10(compConcentration+0.00005), y= RawData))+ #Adding 0.0005 to prevent data loss geom_jitter(aes(colour=compName, shape = expType), width = 0.05)+ theme_bw()+ labs(title = &quot;C. elegans offspring count&quot;, x = &quot;Log 10 compound Concentration (nM)&quot;, y = &quot;C. elegans Counts&quot;) The positive control for this experiment is ethanol. The negative control for this experiment is S-medium. To analyse if there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve it is advisable to make a dosis-response curve (IC50). To make this curve you need to follow the next few steps: 1. Normalize the data to the controlNegative condition. 2. Fit a dose-response curve to the data for each compound using a four-parameter logistic model. 3. Estimate the IC50 value for each compound based on the fitted curve. 4. Compare the IC50 values across the different compounds to see if there are any differences in growth of the C. elegans offspring. 5. Perform statistical tests to determine whether there is a significant effect of concentration on offspring count for each compound. You want to normalize the data to ensure that any differences we observe in the data between the different compounds and concentrations are not simply due to differences in the overall baseline level of the response. 2.4 Normalizing the data # Calculate the normalization factor norm_factor &lt;- mean(elegans_data_tidy$RawData[elegans_data_tidy$expType == &quot;controlNegative&quot;]) # Normalize the data elegans_data_tidy$Normalized &lt;- elegans_data_tidy$RawData / norm_factor # Setting the negative control value to 1 elegans_data_tidy$Normalized[elegans_data_tidy$expType == &quot;Negative Control&quot;] &lt;- 1 # Creating the plot with the normalized data elegans_data_tidy %&gt;% ggplot(aes(x = log10(compConcentration+0.00005), y = Normalized)) + geom_jitter(aes(colour= compName, shape= expType), width = 0.05)+ labs(title = &quot;Normalized C. elegans offspring count&quot;, x = &quot;Compound Concentration (nM)&quot;, y = &quot;Normalized C. elegans Counts&quot;) Based on the graphs above there can be concluded that 2.6-diisopropylnaphtalene, decane and nepthalene all cause a decrease in the amount of C. elegans offspring. "],["scoring-a-publication-on-reproducibility.html", "Chapter 3 Scoring a publication on reproducibility 3.1 Information about the study 3.2 Reproducibility scoring", " Chapter 3 Scoring a publication on reproducibility Often times the used R code for rendering and inspecting data is not visualized in a publication. In this file the article “Meta-Analysis: MRI Volumetric Data of Children with ADHD Subtypes” is tested and scored on reproducibility. The article can be found under the following link: https://osf.io/d97pw/ 3.1 Information about the study The aim of this study was to examine how the ADHD subtypes differentiate based on brain structure volume size. Attention-deficit hyperactivity disorder (ADHD) is a common neurodevelopmental disorder consisting of inattentive and/or hyperactive behaviors that is typically prevalent in childhood. There are three recognized subtypes of this disorder—hyperactive, inattentive, and combined. For this study a meta-analysis was done using 8 studies that included volumetric data of ADHD subtypes (inattentive and combined) in children that was acquired through magnetic resonance imaging (MRI) techniques. Analyses were done looking at combined and inattentive type in comparison to controls and between the two groups. Further subgroup analyses were done on gender and brain regions in the two subtypes. Results show that there is a significant brain volume reduction in combined type in comparison to controls and inattentive type. There is also a significant volume reduction observed in males. The other analyses done yielded insignificant findings, although the volume reduction in inattentive type was only slightly above the cutoff of alpha (0.05). These findings help in better understanding the relations between brain volume and ADHD subtypes, but further research is still needed in this area. 3.2 Reproducibility scoring The article is going to be scored on the basis of ‘Repita’ criteria. The criterea will be scored on a scale from 1 (very hard) to 5 (very easy). More information about these criteria can be found under the following link: https://www.researchgate.net/publication/340244621_Reproducibility_and_reporting_practices_in_COVID-19_preprint_manuscripts Transparency Criteria Score on a 1-5 scale Study Purpose 4 Data Availability Statement 4 Data Location 5 Study Location 3 Author Review 4 Ethics Statement 3 Funding Statement 1 Code Availability 5 ## Running the open source code The file “HYSELL_Meta_Studies.xlsx” was downloaded of the site to run the code and see if it is reproducible. In terms of the readability of the code i would grade the code a score of 4 out of 5. When running the script i have not encountered major difficulties with visualizing a figure. The only thing i had to change from the original script is the function “plyr::revalue”. Rstudio did not reconize this function. With this in mind i have changed this piece of the code to “dplyr::recode”. Taken together on a scale from 1 (very hard) to 5 (very easy) it took much effort to reproduce the visualization of the data. With this in mind i would score the article a 4 out of 5. library(dplyr) library(metafor) library(tidyverse) library(robumeta) library(readxl) HYSELL_Meta_Studies &lt;- read_excel(&quot;C:/Users/diand/OneDrive/Documenten/DSFB2/dsfb2_workflows_portfolio/Portfolio/Reproducibility of scientific publications/Data_raw/HYSELL_Meta_Studies.xlsx&quot;) # Convert ABB column to factor HYSELL_Meta_Studies$stype &lt;- as.factor(HYSELL_Meta_Studies$ABB) # Mutate stype column using dplyr::recode HYSELL_Meta_Studies &lt;- HYSELL_Meta_Studies %&gt;% mutate(stype = dplyr::recode(ABB, &quot;C&quot; = &quot;0&quot;, &quot;IA&quot; = &quot;1&quot;)) ## tn: Treatment Group Sample size ## cn: control Group Sample size ## tmean: Treatment Group Mean ## cmean: Control Group Mean ## tsd: Treatment Group Standard Deviation ## csd: Control Group Standard Deviation ##Effect Size Calculation #Cohen&#39;s d #Common Components HYSELL_Meta_Studies$IG_totaln &lt;- with(HYSELL_Meta_Studies, tn+cn) HYSELL_Meta_Studies$IG_multin &lt;- with(HYSELL_Meta_Studies, tn*cn) #Step 1. Pooled Standard Deviation HYSELL_Meta_Studies$s_pool &lt;- with(HYSELL_Meta_Studies, sqrt(((tn-1)*(tsd^2)+(cn-1)*(csd^2))/(IG_totaln-2))) #Step 2. Effect Size HYSELL_Meta_Studies$IG_d &lt;- with(HYSELL_Meta_Studies, (tmean-cmean)/s_pool) #Step 3. Sampling Variance HYSELL_Meta_Studies$IG_se &lt;- with(HYSELL_Meta_Studies, (IG_totaln/IG_multin)+(IG_d^2/(2*IG_totaln))) ## MERGE Cohen&#39;s d Effect Size into one column HYSELL_Meta_Studies$Cohen_es &lt;-rowSums(select(HYSELL_Meta_Studies, ends_with(&quot;_d&quot;)), na.rm=T) HYSELL_Meta_Studies$Cohen_v &lt;-rowSums(select(HYSELL_Meta_Studies, ends_with(&quot;_se&quot;)), na.rm=T) #column for effect size and sampling variance #Based on Cohen&#39;s d, HYSELL_Meta_Studies$Cohen_es &lt;- as.numeric(HYSELL_Meta_Studies$Cohen_es, na.rm=TRUE) HYSELL_Meta_Studies$Cohen_v &lt;- as.numeric(HYSELL_Meta_Studies$Cohen_v, na.rm=TRUE) ##Bias-Corrected Standardized Mean Difference (Hedges&#39; g) from Cohen&#39;s d #Correction Factor (J) #Reclassified effect size IG ( =1) HYSELL_Meta_Studies$df &lt;- HYSELL_Meta_Studies$IG_totaln-2 HYSELL_Meta_Studies$g_j &lt;- 1-(3/((4*HYSELL_Meta_Studies$df)-1)) HYSELL_Meta_Studies$g_es_all &lt;- with(HYSELL_Meta_Studies, Cohen_es*g_j) HYSELL_Meta_Studies$g_v_all &lt;- with(HYSELL_Meta_Studies, Cohen_v*g_j^2) ## Random Effect thesis_ran_model &lt;- rma(g_es_all, g_v_all, data = HYSELL_Meta_Studies) thesis_ran_model ## ## Random-Effects Model (k = 95; tau^2 estimator: REML) ## ## tau^2 (estimated amount of total heterogeneity): 0.0492 (SE = 0.0133) ## tau (square root of estimated tau^2 value): 0.2218 ## I^2 (total heterogeneity / total variability): 66.31% ## H^2 (total variability / sampling variability): 2.97 ## ## Test for Heterogeneity: ## Q(df = 94) = 239.2705, p-val &lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## -0.1799 0.0325 -5.5306 &lt;.0001 -0.2437 -0.1162 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #Number of effect sizes: 95 #Pooled Effect size: -0.1799 #Standard error of pooled effect size: 0.0325 #95% Confidence interval: [-0.2437, -0.1162] #p-value: &lt;.0001 # Q-statistic = 239.2705 # df = 94 # p-val = &lt; 0.0001 #Interpretation: # Moderator Analysis: Comparing inattentive with combined: a Q-test based on analysis of variance moder1_t &lt;- rma(g_es_all, g_v_all, data=HYSELL_Meta_Studies, subset=stype== 0) # For combined group (=0) moder2_t &lt;- rma(g_es_all, g_v_all, data=HYSELL_Meta_Studies, subset=stype== 1) # For inattentive group (=1) moder1_t ## ## Random-Effects Model (k = 52; tau^2 estimator: REML) ## ## tau^2 (estimated amount of total heterogeneity): 0.0965 (SE = 0.0296) ## tau (square root of estimated tau^2 value): 0.3106 ## I^2 (total heterogeneity / total variability): 79.80% ## H^2 (total variability / sampling variability): 4.95 ## ## Test for Heterogeneity: ## Q(df = 51) = 143.6559, p-val &lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## -0.2564 0.0547 -4.6830 &lt;.0001 -0.3637 -0.1491 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 moder2_t ## ## Random-Effects Model (k = 43; tau^2 estimator: REML) ## ## tau^2 (estimated amount of total heterogeneity): 0.0078 (SE = 0.0069) ## tau (square root of estimated tau^2 value): 0.0881 ## I^2 (total heterogeneity / total variability): 22.52% ## H^2 (total variability / sampling variability): 1.29 ## ## Test for Heterogeneity: ## Q(df = 42) = 60.5712, p-val = 0.0316 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## -0.0579 0.0309 -1.8701 0.0615 -0.1185 0.0028 . ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Pooled Effect size combined type: -0.2564 (SE = 0.0547, p &lt;.0001) # Within-variance, Q(df = 51) = 143.6559, p-val &lt;.0001 # Pooled Effect size for inattentive type: -0.0579 (SE = 0.0309, p= 0.0615) # Within-variance, Q(df = 42) = 60.5712, p-val = 0.0316 # Overall pooled Effect size: -0.1799 (SE = 0.0325, p &lt;.0001) # Total Variance Q(df = 94) = 239.2705,, p-val &lt; .0001 143.6559 + 60.5712 ## [1] 204.2271 # Qwithin = 204.2271 239.2705 - (143.6559 + 60.5712) ## [1] 35.0434 # Qbetween = 35.0434 # Test under chi-square distribution (Q-statistic follows chi-square dsictribution.) pchisq(35.0434, df=1, lower.tail=FALSE) ## [1] 3.22438e-09 # p-value for the Qbetween is 3.22438e-09 (less than alpha-level, 0.05). # We found that the Q-between (35.0434) is significant (p &lt; 0.05) indicating # two groups have statistically different pooled effect sizes. ## Meta-regression without and with &quot;% of male&quot; moderator # Centering the moderator mean(HYSELL_Meta_Studies$m2f) ## [1] 0.7951579 HYSELL_Meta_Studies$m2f_c &lt;- HYSELL_Meta_Studies$m2f - 0.795 ## RVE (Considering dependency among multiple effect sizes within a study) RVE_thesis &lt;- robu(formula = g_es_all ~ 1, data=HYSELL_Meta_Studies, studynum=studyid, var.eff.size=g_v_all, modelweights = &quot;CORR&quot;, small = TRUE) RVE_thesis ## RVE: Correlated Effects Model with Small-Sample Corrections ## ## Model: g_es_all ~ 1 ## ## Number of studies = 8 ## Number of outcomes = 95 (min = 4 , mean = 11.9 , median = 8 , max = 24 ) ## Rho = 0.8 ## I.sq = 64.62675 ## Tau.sq = 0.09790346 ## ## Estimate StdErr t-value dfs P(|t|&gt;) 95% CI.L 95% CI.U Sig ## 1 X.Intercept. -0.163 0.0701 -2.33 6.45 0.0556 -0.332 0.00523 * ## --- ## Signif. codes: &lt; .01 *** &lt; .05 ** &lt; .10 * ## --- ## Note: If df &lt; 4, do not trust the results #Number of effect sizes: 95 #Number of studies: 8 #Pooled Effect size: -0.163 #Standard error of pooled effect size: 0.0701 #95% Confidence interval: [-0.332, 0.00523] #p-value: 0.0556 # Tau-square: 0.09790346 #RVE with moderator RVE_thesis1 &lt;- robu(formula = g_es_all ~ m2f_c, data=HYSELL_Meta_Studies, studynum=studyid, var.eff.size=g_v_all, modelweights = &quot;CORR&quot;, small = TRUE) RVE_thesis1 ## RVE: Correlated Effects Model with Small-Sample Corrections ## ## Model: g_es_all ~ m2f_c ## ## Number of studies = 8 ## Number of outcomes = 95 (min = 4 , mean = 11.9 , median = 8 , max = 24 ) ## Rho = 0.8 ## I.sq = 62.06272 ## Tau.sq = 0.08758224 ## ## Estimate StdErr t-value dfs P(|t|&gt;) 95% CI.L 95% CI.U Sig ## 1 X.Intercept. -0.148 0.0468 -3.16 5.53 0.0219 -0.264 -0.0308 ** ## 2 m2f_c -1.105 0.2403 -4.60 2.74 0.0235 -1.913 -0.2971 ** ## --- ## Signif. codes: &lt; .01 *** &lt; .05 ** &lt; .10 * ## --- ## Note: If df &lt; 4, do not trust the results #Number of effect sizes: 95 #Number of studies: 8 #Pooled Effect size: -0.148 #Standard error of pooled effect size: 0.0468 #95% Confidence interval: [-0.264, -0.0308] #p-value: 0.0219 # Tau-square: 0.08758224 #Pooled Effect size for gender: -1.105 #Standard error of pooled effect size for gender: 0.2403 #95% Confidence interval for gender: [-1.913, -0.2971] #p-value gender: 0.0235 ## Make Forest plot forest(thesis_ran_model, slab = paste(HYSELL_Meta_Studies$Authors), xlim = c(-2,2), cex = 0.5) op &lt;- par(cex = 0.75, font = 10) text(-3, 98, &quot;Author and Year&quot;, pos = 4) text(2, 98, &quot;Hedges&#39;g [95% CI]&quot;, pos = 2) par(op) "],["guerrilla-analytics-structure.html", "Chapter 4 Guerrilla analytics structure", " Chapter 4 Guerrilla analytics structure The folder tree below shows my folder structure of the DAUR2 lessons. These lessons were are a part of the data science for biology 1 course. folder tree fs::dir_tree(here::here(\"Guerrilla_analytics_framework\", \"Data_daur2\")) "],["curriculum-vitae.html", "Chapter 5 Curriculum vitae”", " Chapter 5 Curriculum vitae” 5.0.1 Personalia Naam: Dian Dupon Adres: Telefoon: E-mail: dian.dupon@student.hu.nl Geslacht: vrouw Geboortedatum: Nationaliteit: Nederlandse Rijbewijs: Ja 5.0.2 Profiel Ik ben een enthousiaste leerling. Bij het uitvoeren van een experiment ben ik altijd nieuwsgierig naar de uitslag. Dit motiveert mij dan ook om een zo goed en zo nauwkeurig mogelijke uitslag te krijgen. In de opleiding heb ik vaak te maken met deadlines. Hier kan ik goed mee omgaan. 5.0.3 Opleidingen 2020 – 2024, Biologie en medisch laboratoriumonderzoek, HBO aan de Hogeschool Utrecht 2016 – 2020, Biomedisch analist, MBO niveau 4 aan het Nova College te Beverwijk, diploma 2012 – 2016, Saenredam College te Zaandijk, vmbo-tl, diploma 5.0.4 Werkervaring Albert Heijn te Zaandam Maart 2019 – april 2023 Functiebenaming: medewerker vers Expertisecentrum Leptospirose te Amsterdam Januari 2020 – juli 2020 Functiebenaming: stagiaire Sanquin bloedvoorziening te Amsterdam Augustus 2018 – januari 2019 Functiebenaming: stagiaire Dekamarkt te Zaandam November 2016 – december 2018 Functiebenaming: vakkenvuller 5.0.5 Vaardigheden • (q)PCR • MALDI-TOF MS • VITEK2 • ELISA • Western blot "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
